{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68b82c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64843719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate_metrics function will take the actual and predicted values as input\n",
    "# and return overall accuracy, precision and recall as output\n",
    "def calculate_metrics(actual, predicted):\n",
    "\n",
    "    y_actu = pd.DataFrame(actual, columns=[\"Actual\"])\n",
    "    y_pred = pd.DataFrame(predicted, columns=[\"Predicted\"])\n",
    "    \n",
    "    confusion_matrix = pd.crosstab(y_actu[\"Actual\"], y_pred[\"Predicted\"])\n",
    "\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "    \n",
    "    del(confusion_matrix)\n",
    "\n",
    "    # Recall, the proportion of true positive predictions\n",
    "    # out of all actual positive cases.\n",
    "    recall = TP / (TP + FN) * 100\n",
    "\n",
    "    # Precision, the proportion of true positive predictions\n",
    "    # out of all positive predictions made by the model.\n",
    "    precision = TP / (TP + FP) * 100\n",
    "\n",
    "    # Accuracy, the proportion of correct predictions made by the model.\n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN) * 100\n",
    "\n",
    "    # These values are calculated for each class, and then averaged to get the overall score.\n",
    "    \n",
    "    return (recall.mean(), precision.mean(), accuracy.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5b7d77",
   "metadata": {},
   "source": [
    "I used matrix multiplication: euclidean distance matrix = sqrt(p1 + p2 + p3)\n",
    "\n",
    "\n",
    "p1 = sum of squares of rows of train matrix\n",
    "\n",
    "p2 = sum of squares of rows of test matrix\n",
    "\n",
    "p3 = -2 * dot product of rows of train matrix and transpose of test matrix\n",
    "\n",
    "If I have two test vectors and 8 train vectors, than I'll recieve a matrix that consists of 8 rows and 2 columns, each column has the distances of a test vector to every train vector. For example:\n",
    "\n",
    "                     test_vector_1 test_vector_2\n",
    "                 \n",
    "    train_vector_1   [[9.69535971  14.31782106]\n",
    "\n",
    "    train_vector_2   [10.44030651 14.76482306]\n",
    "\n",
    "    train_vector_3   [10.39230485 14.45683229]\n",
    "\n",
    "        etc.         [11.87434209 14.69693846]\n",
    "\n",
    "                     [8.83176087  9.21954446]\n",
    "\n",
    "                     [9.16515139  12.68857754]\n",
    "\n",
    "                     [11.87434209 16.30950643]\n",
    "\n",
    "                     [8.60232527  14.59451952]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e92bf96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(a, axis=0):\n",
    "    scores = np.unique(np.ravel(a))  # unique values\n",
    "    testshape = list(a.shape)\n",
    "    testshape[axis] = 1\n",
    "    oldmostfreq = np.zeros(testshape)\n",
    "    oldcounts = np.zeros(testshape)\n",
    "\n",
    "    for score in scores:\n",
    "        template = a == score\n",
    "        counts = np.expand_dims(np.sum(template, axis), axis)\n",
    "        mostfrequent = np.where(counts > oldcounts, score, oldmostfreq)\n",
    "        oldcounts = np.maximum(counts, oldcounts)\n",
    "        oldmostfreq = mostfrequent\n",
    "\n",
    "    return mostfrequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "256edc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train_data, test_data, k):\n",
    "    # keep the Personality type column in a separate variable\n",
    "    train_personalities = train_data[:, -1]\n",
    "\n",
    "    # drop the Personality type column from the train data\n",
    "    train_data = train_data[:, :-1]\n",
    "\n",
    "    # calculate the first part of the distance formula\n",
    "    first_term = np.sum(train_data**2, axis=1)[:, np.newaxis]\n",
    "\n",
    "    # calculate the second part of the distance formula\n",
    "    second_term = np.sum(test_data**2, axis=1)\n",
    "\n",
    "    # calculate the third part of the distance formula\n",
    "    third_term = -2 * np.dot(train_data, test_data.T)\n",
    "    \n",
    "    del train_data #trying to optimize memory\n",
    "    \n",
    "    # calculate the Euclidean distance matrix\n",
    "    distance_matrix = np.sqrt(first_term + second_term + third_term)\n",
    "\n",
    "    # get the indices of the k nearest neighbors for each column in the test data\n",
    "    k_nearest_neighbors = np.argsort(distance_matrix, axis=0)[:k]\n",
    "    \n",
    "    del distance_matrix #trying to optimize memory\n",
    "    \n",
    "    # get the personalities (labels) of the k nearest neighbors\n",
    "    nearest_personalities = train_personalities[k_nearest_neighbors]\n",
    "    \n",
    "    #find the most frequent element in each column\n",
    "    predicted = most_frequent(nearest_personalities)[0]\n",
    "    \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5264fac9",
   "metadata": {},
   "source": [
    "I use 5 fold cross validation function five_fold_cross() which splits data to 5 folds (12.000 row each fold). \n",
    "First, I split my data array to 5 pieces with np.array_split(). Then, I use a for loop to iterate through folds. In every iteration: \n",
    "\n",
    "I choose one fold as my test_data, and use np.concatenate() to combine other 4 folds to use as train_data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a82fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_fold_cross_val_score(data, k, predict_func):\n",
    "    fold = 5\n",
    "\n",
    "    # split the data into folds\n",
    "    folds_list = np.array_split(data, fold)  # 5 folds of 12.000 rows\n",
    "\n",
    "    total_accuracy = 0\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "\n",
    "    # iterate over the folds\n",
    "    for i in range(fold):\n",
    "        # concatenate the folds except the current one to get the training data\n",
    "        train = np.concatenate(folds_list[:i] + folds_list[i + 1 :])\n",
    "\n",
    "        # get the test data\n",
    "        test = folds_list[i]\n",
    "\n",
    "        # actual Personality type\n",
    "        actual = test[:, -1]\n",
    "\n",
    "        # drop the Personality type column\n",
    "        test = test[:, :-1]\n",
    "        \n",
    "        predicted = predict_func(train, test, k)\n",
    "    \n",
    "\n",
    "        # current accuracy, precision, recall\n",
    "        (cur_rec, cur_pre, cur_acc) = calculate_metrics(actual, predicted)\n",
    "\n",
    "        total_accuracy += cur_acc\n",
    "        total_precision += cur_pre\n",
    "        total_recall += cur_rec\n",
    "        \n",
    "    return (total_accuracy / fold, total_precision / fold, total_recall / fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd4d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for personality types\n",
    "personality_dict = {\n",
    "    \"ESTJ\": 0,\n",
    "    \"ENTJ\": 1,\n",
    "    \"ESFJ\": 2,\n",
    "    \"ENFJ\": 3,\n",
    "    \"ISTJ\": 4,\n",
    "    \"ISFJ\": 5,\n",
    "    \"INTJ\": 6,\n",
    "    \"INFJ\": 7,\n",
    "    \"ESTP\": 8,\n",
    "    \"ESFP\": 9,\n",
    "    \"ENTP\": 10,\n",
    "    \"ENFP\": 11,\n",
    "    \"ISTP\": 12,\n",
    "    \"ISFP\": 13,\n",
    "    \"INTP\": 14,\n",
    "    \"INFP\": 15,\n",
    "}\n",
    "\n",
    "\n",
    "# nrows is max read rows\n",
    "df = pd.read_csv(\"16P.csv\", encoding=\"cp1252\")\n",
    "\n",
    "# drop response id\n",
    "df = df.drop(\"Response Id\", axis=\"columns\")\n",
    "\n",
    "# encode \"personality\" column of df to numbers in typeDict\n",
    "df[\"Personality\"] = df[\"Personality\"].map(personality_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9754c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataframe to numpy array\n",
    "df_arr = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1e3776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k values\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "# accuracy values corresponding to each k value\n",
    "accuracy = []\n",
    "\n",
    "# accuracy values corresponding to each k value\n",
    "precision = []\n",
    "\n",
    "# accuracy values corresponding to each k value\n",
    "recall = []\n",
    "\n",
    "#runtime corresponding to each k value\n",
    "times = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956674fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 1\n"
     ]
    }
   ],
   "source": [
    "for k in k_values:\n",
    "    print(\"For k =\", k)\n",
    "    start = time.time()\n",
    "    (acc, prec, rec) = five_fold_cross_val_score(df_arr, k,predict)\n",
    "    end = time.time()\n",
    "    print(\"Recall:\", rec)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Elapsed time:\", time.strftime(\"%H:%M:%S\", time.gmtime(end - start)), \"\\n\")\n",
    "    \n",
    "    accuracy.append(acc)\n",
    "    precision.append(prec)\n",
    "    recall.append(rec)\n",
    "    times.append(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1290bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_values, accuracy)\n",
    "\n",
    "plt.title(\"Accuracy - k Graph\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(k_values, precision)\n",
    "\n",
    "plt.title(\"Precision - k Graph\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Precision\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(k_values, recall)\n",
    "\n",
    "plt.title(\"Recall - k Graph\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Recall\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(k_values, times)\n",
    "\n",
    "plt.title(\"Time - k Graph\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Time\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e3cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_predict(train_data, test_data, k):\n",
    "    pred_list = [] \n",
    "    \n",
    "    # keep the Personality type column in a separate variable\n",
    "    train_personalities = train_data[:, -1]\n",
    "\n",
    "    # drop the Personality type column from the train data\n",
    "    train_data = train_data[:, :-1]\n",
    "\n",
    "    # calculate the first part of the distance formula\n",
    "    first_term = np.sum(train_data**2, axis=1)[:, np.newaxis]\n",
    "\n",
    "    # calculate the second part of the distance formula\n",
    "    second_term = np.sum(test_data**2, axis=1)\n",
    "\n",
    "    # calculate the third part of the distance formula\n",
    "    third_term = -2 * np.dot(train_data, test_data.T)\n",
    "    \n",
    "    del train_data #trying to optimize memory\n",
    "\n",
    "    # calculate the Euclidean distance matrix\n",
    "    distance_matrix = np.sqrt(first_term + second_term + third_term)\n",
    "\n",
    "    # get the indices of the k nearest neighbors for each column in the test data\n",
    "    k_nearest_neighbors = np.argsort(distance_matrix, axis=0)[:k]\n",
    "    \n",
    "    del distance_matrix #trying to optimize memory\n",
    "    \n",
    "    # get the personalities (labels) of the k nearest neighbors\n",
    "    nearest_personalities = train_personalities[k_nearest_neighbors]\n",
    "    \n",
    "    #get weights\n",
    "    weights = (1/k_nearest_neighbors)\n",
    "    \n",
    "    for col in range(test_data.shape[1]):\n",
    "        #key is the personality type, value is the total weight\n",
    "        weight_dict = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0}\n",
    "\n",
    "        #key is the personality type, value is the number it's occured\n",
    "        encounter_dict = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0}\n",
    "\n",
    "        for i in range(len(nearest_personalities[col])):\n",
    "            weight_dict[nearest_personalities[col][i]] += weights[col][i]\n",
    "            encounter_dict[nearest_personalities[col][i]] += 1\n",
    "\n",
    "        for j in range(len(nearest_personalities[col])):\n",
    "            weight_dict[nearest_personalities[col][i]] = weight_dict[nearest_personalities[col][i]] / encounter_dict[nearest_personalities[col][i]]\n",
    "\n",
    "        predicted = 0\n",
    "        max_value = -1\n",
    "        max_index = -1\n",
    "        values = list(weight_dict.values())\n",
    "\n",
    "        for k in range(len(values)):\n",
    "            if values[k] >=  max_value:\n",
    "                max_value = values[k]\n",
    "                max_index = k\n",
    "\n",
    "        predicted = list(weight_dict.keys())[max_index]\n",
    "        pred_list.append(predicted)\n",
    "    \n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy values corresponding to each k value\n",
    "accuracy_wkk = []\n",
    "\n",
    "# accuracy values corresponding to each k value\n",
    "precision_wkk = []\n",
    "\n",
    "# accuracy values corresponding to each k value\n",
    "recall_wkk = []\n",
    "\n",
    "#runtime corresponding to each k value\n",
    "times_wkk = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f58b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    print(\"For k =\", k)\n",
    "    start = time.time()\n",
    "    (acc, prec, rec) = five_fold_cross_val_score(df_arr, k,weighted_predict)\n",
    "    end = time.time()\n",
    "    print(\"Recall:\", rec)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Elapsed time:\", time.strftime(\"%H:%M:%S\", time.gmtime(end - start)), \"\\n\")\n",
    "    \n",
    "    accuracy_wkk.append(acc)\n",
    "    precision_wkk.append(prec)\n",
    "    recall_wkk.append(rec)\n",
    "    times_wkk.append(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b023cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_values, accuracy_wkk)\n",
    "\n",
    "plt.title(\"Weighted Accuracy - k Graph\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(k_values, precision_wkk)\n",
    "\n",
    "plt.title(\"Weighted Precision - k Graph\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Precision\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(k_values, recall_wkk)\n",
    "\n",
    "plt.title(\"Weighted Recall - k Graph\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Recall\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(k_values, times_wkk)\n",
    "\n",
    "plt.title(\"Weighted Time - k Graph\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Time\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b929730",
   "metadata": {},
   "source": [
    "feature_scale function will apply a min-max normalization on the data. \n",
    "Every row has 60 independent variables, a.k.a. 60 feature columns, each feature column will be scaled between \n",
    "0 and 1 using min-max normalization with the formula: \n",
    "\n",
    "scaled_row = (row - min(row)) / (max(row) - min(row))\n",
    "\n",
    "where min(row) is the minimum value of the row and max(row) is the maximum value of the row. \n",
    "In our case, min(row) is always -3 and max(row) is always 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92edc582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scale(data):\n",
    "    possible_min = -3\n",
    "    possible_max = 3\n",
    "\n",
    "    denominator = (possible_max - possible_min)  # didn't want to calculate this every time since it's constant\n",
    "\n",
    "\n",
    "    return (data - possible_min) / (denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0067a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep the personality colunmn so that it won't get normalized\n",
    "temp_personality_column = df_arr[:, -1]\n",
    "\n",
    "#drop the personality column\n",
    "df_arr = df_arr[:, :-1]\n",
    "\n",
    "#scale the array\n",
    "df_arr = feature_scale(df_arr)\n",
    "\n",
    "#add the original personality column again\n",
    "df_arr = np.column_stack((df_arr, temp_personality_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cda3a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy values corresponding to each k value\n",
    "accuracy_scaled = []\n",
    "\n",
    "# accuracy values corresponding to each k value\n",
    "precision_scaled = []\n",
    "\n",
    "# accuracy values corresponding to each k value\n",
    "recall_scaled = []\n",
    "\n",
    "#runtime corresponding to each k value\n",
    "times_scaled = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed5da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After data is SCALED\\n---------------\\n\")\n",
    "for k in k_values:\n",
    "    print(\"For k =\", k)\n",
    "    start = time.time()\n",
    "    (acc, prec, rec) = five_fold_cross_val_score(df_arr, k)\n",
    "    end = time.time()\n",
    "    print(\"Recall:\", rec)\n",
    "    print(\"Precision:\", prec)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Elapsed time:\", time.strftime(\"%H:%M:%S\", time.gmtime(end - start)), \"\\n\")\n",
    "    \n",
    "    accuracy_scaled.append(acc)\n",
    "    precision_scaled.append(prec)\n",
    "    recall_scaled.append(rec)\n",
    "    times_scaled.append(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9663c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_values, accuracy, color='r', label='No scale')\n",
    "plt.plot(k_values, accuracy_scaled, color='g', label='Scaled')\n",
    "  \n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Change of Accuracy With Normalization\")\n",
    "  \n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(k_values, precision, color='r', label='No scale')\n",
    "plt.plot(k_values, precision_scaled, color='g', label='Scaled')\n",
    "\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Change of Precision With Normalization\")\n",
    "\n",
    "plt.legend()\n",
    "  \n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(k_values, recall, color='r', label='No scale')\n",
    "plt.plot(k_values, recall_scaled, color='g', label='Scaled')\n",
    "  \n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.title(\"Change of Recall With Normalization\")\n",
    "  \n",
    "plt.legend()\n",
    "  \n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(k_values, times, color='r', label='No scale')\n",
    "plt.plot(k_values, times_scaled, color='g', label='Scaled')\n",
    "  \n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Runtime (minutes)\")\n",
    "plt.title(\"Change of Runtime With Normalization\")\n",
    "  \n",
    "plt.legend()\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14c8506",
   "metadata": {},
   "source": [
    "Error Analysis\n",
    "\n",
    "I observed some miscorrect guesses while testing. I realised some possible reasons:\n",
    "\n",
    "    1. Since the algorithm is based on finding nearest neighbours and choosing the most frequently seen among them (plurality voting), if we don't have a frequent neighbour (for example if we're experimenting with k = 3 and every one of the k - nearest distances are unique), then my model tend to make mistakes. Because I use argmax to find the maximum repeated distance, and it'll return the first occured if their frequencies is same.  ( np.argmax([1,1,1]) --> 0 )\n",
    "\n",
    "    2. Especially using k = 1 drastically decreases my model's correctness. Which that makes sence since I just sort the distances and get the first lowest distance, don't check if there're any other distances, don't check the frequencies etc. \n",
    "\n",
    "    3. I tried to check if the misclassified samples all have similar characteristics, couldn't find a strong correlation among them that's strong enough to convince me. I checked my confusion matrix (16 x 16, prints the actual and predicted values with respect to each personality), errors seemed homogenously distributed. \n",
    "\n",
    "    4. Another hypothesis of mine was if there's a case of \"class imbalance\", that is if one class is overrepresented, making it hard for my model to learn the other classes. That doesn't seem like the case neither. Every personality type seems almost equally distrubited to data.\n",
    "\n",
    "\n",
    "Performance Analysis\n",
    "\n",
    "All of my recall, precision and accuracy values seems to be increasing with k value between 1 - 5. So k = 3 is better than k = 1, k = 5 is better than k = 3. Between 5 - 7, increase continues but acceleration decreases. \n",
    "\n",
    "Also, all of the values are better in general when data is scaled.\n",
    "\n",
    "When it comes to time, it has a sharp decrease between K = 1 and K = 3, which I don't know, it seems counter-intuitive to me. It may be related to my system. Between scaled and non-scaled data, scaled performs better in terms of running time. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
